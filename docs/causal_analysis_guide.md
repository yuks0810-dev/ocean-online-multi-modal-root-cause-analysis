# OCEAN ã«ã‚ˆã‚‹å› æœé–¢ä¿‚æŠ½å‡ºã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

OCEANãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹é–“ã®å› æœé–¢ä¿‚ã‚’æŠ½å‡ºã—ã€æ ¹æœ¬åŸå› åˆ†æã‚’è¡Œã†æ–¹æ³•ã‚’è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

## å› æœé–¢ä¿‚æŠ½å‡ºã®ä»•çµ„ã¿

### 1. Multi-factor Attention ã«ã‚ˆã‚‹å› æœé–¢ä¿‚æ¨å®š

OCEANãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®æ–¹æ³•ã§å› æœé–¢ä¿‚ã‚’æŠ½å‡ºã—ã¾ã™ï¼š

```python
# æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹é‡è¦åº¦è¨ˆç®—
attention_weights = multi_factor_attention(temporal_features, spatial_features, log_features)

# å› æœé–¢ä¿‚ã‚¹ã‚³ã‚¢ = æ³¨æ„é‡ã¿ Ã— æ™‚ç³»åˆ—ç›¸é–¢ Ã— ã‚°ãƒ©ãƒ•æ§‹é€ 
causality_score = attention_weights * temporal_correlation * graph_adjacency
```

### 2. å¯¾æ¯”å­¦ç¿’ã«ã‚ˆã‚‹ç‰¹å¾´è¡¨ç¾

```python
# InfoNCEæå¤±ã«ã‚ˆã‚‹è¡¨ç¾å­¦ç¿’
contrastive_loss = info_nce_loss(positive_pairs, negative_pairs)

# å­¦ç¿’ã•ã‚ŒãŸè¡¨ç¾ã‹ã‚‰å› æœé–¢ä¿‚ã‚’æ¨å®š
causal_embeddings = contrastive_learning_module(multimodal_features)
```

## å®Ÿè·µçš„ãªä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªå› æœé–¢ä¿‚æŠ½å‡º

```python
from causal_extraction_example import CausalRelationshipExtractor
from ocean.models.ocean_model import OCEANModel
from ocean.configs.default_config import default_config

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
config = default_config()
model = OCEANModel(config)
model.eval()

# å› æœé–¢ä¿‚æŠ½å‡ºå™¨ã®ä½œæˆ
service_names = ['web', 'api', 'db', 'cache', 'queue']
extractor = CausalRelationshipExtractor(model, service_names)

# å› æœé–¢ä¿‚ã®æŠ½å‡º
results = extractor.extract_causal_relationships(
    metrics=time_series_data,      # (batch, seq_len, features)
    service_graph=service_graph,   # ServiceGraph object
    logs=log_embeddings,           # (batch, seq_len, log_dim)
    threshold=0.5                  # æ ¹æœ¬åŸå› ã®ç¢ºä¿¡åº¦é–¾å€¤
)
```

### çµæœã®è§£é‡ˆ

æŠ½å‡ºã•ã‚ŒãŸå› æœé–¢ä¿‚ã¯ä»¥ä¸‹ã®å½¢å¼ã§è¿”ã•ã‚Œã¾ã™ï¼š

```python
{
    'root_cause_probabilities': np.ndarray,  # å„ã‚µãƒ¼ãƒ“ã‚¹ã®æ ¹æœ¬åŸå› ç¢ºç‡
    'causal_relationships': {
        'cross_modal_attention': {},      # ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«æ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³
        'temporal_dependencies': {},      # æ™‚ç³»åˆ—ä¾å­˜é–¢ä¿‚
        'spatial_relationships': {}       # ç©ºé–“çš„é–¢ä¿‚
    },
    'service_influences': {},             # ã‚µãƒ¼ãƒ“ã‚¹é–“å½±éŸ¿åº¦
    'temporal_causality': {},             # æ™‚ç³»åˆ—å› æœé–¢ä¿‚
    'summary': {}                         # åˆ†æè¦ç´„
}
```

## å› æœé–¢ä¿‚ã®ç¨®é¡

### 1. ç›´æ¥çš„å› æœé–¢ä¿‚

ã‚µãƒ¼ãƒ“ã‚¹Aã®ç•°å¸¸ãŒç›´æ¥çš„ã«ã‚µãƒ¼ãƒ“ã‚¹Bã«å½±éŸ¿ã‚’ä¸ãˆã‚‹é–¢ä¿‚ï¼š

```
Database Error â†’ User Service Timeout â†’ API Gateway Slow Response
```

### 2. é–“æ¥çš„å› æœé–¢ä¿‚

è¤‡æ•°ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’çµŒç”±ã—ã¦ä¼æ’­ã™ã‚‹å½±éŸ¿ï¼š

```
Cache Miss â†’ Database Overload â†’ Multiple Service Degradation
```

### 3. å…±é€šåŸå› 

åŒä¸€ã®æ ¹æœ¬åŸå› ãŒè¤‡æ•°ã®ã‚µãƒ¼ãƒ“ã‚¹ã«åŒæ™‚ã«å½±éŸ¿ï¼š

```
Network Issue â†’ Web Frontend + API Gateway + Database (All affected)
```

## å®Ÿéš›ã®ã‚·ãƒŠãƒªã‚ªä¾‹

### ã‚·ãƒŠãƒªã‚ª1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹éè² è·

```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ç•°å¸¸ãŒç™ºç”Ÿã™ã‚‹ã‚·ãƒŠãƒªã‚ª
def database_overload_scenario():
    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ç•°å¸¸ã‚’æ¨¡æ“¬
    metrics[anomaly_start:, db_idx] += 3.0  # CPUä½¿ç”¨ç‡ä¸Šæ˜‡
    metrics[anomaly_start+1:, user_service_idx] += 2.0  # ä¾å­˜ã‚µãƒ¼ãƒ“ã‚¹ã¸ã®å½±éŸ¿
    metrics[anomaly_start+2:, api_idx] += 1.0  # ä¸Šæµã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ³¢åŠ
    
    # å› æœé–¢ä¿‚æŠ½å‡º
    results = extractor.extract_causal_relationships(metrics, service_graph)
    
    # æœŸå¾…ã•ã‚Œã‚‹çµæœ:
    # - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæœ€é«˜ç¢ºç‡ã®æ ¹æœ¬åŸå› 
    # - user-service â†’ api ã®é †ã§å½±éŸ¿ãŒä¼æ’­
    # - æ™‚ç³»åˆ—çš„ã«é…å»¶ã‚’æŒã£ãŸå› æœé–¢ä¿‚ãŒæ¤œå‡º
```

### ã‚·ãƒŠãƒªã‚ª2: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ–­

```python
def network_partition_scenario():
    # è¤‡æ•°ã‚µãƒ¼ãƒ“ã‚¹ãŒåŒæ™‚ã«å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚·ãƒŠãƒªã‚ª
    affected_services = ['web', 'api', 'cache']
    
    for service in affected_services:
        service_idx = service_names.index(service)
        metrics[anomaly_start:, service_idx] += 2.5
    
    # å› æœé–¢ä¿‚æŠ½å‡º
    results = extractor.extract_causal_relationships(metrics, service_graph)
    
    # æœŸå¾…ã•ã‚Œã‚‹çµæœ:
    # - è¤‡æ•°ã®æ ¹æœ¬åŸå› å€™è£œ
    # - å…±é€šã®æ™‚åˆ»ã§ã®ç•°å¸¸é–‹å§‹
    # - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£ã®å…±é€šå› å­ãŒæ¤œå‡º
```

## é«˜åº¦ãªåˆ†ææ‰‹æ³•

### 1. æ™‚ç³»åˆ—ãƒ©ã‚°åˆ†æ

```python
def analyze_causal_lags(temporal_features, window_size=5):
    """å› æœé–¢ä¿‚ã®æ™‚é–“çš„é…å»¶ã‚’åˆ†æ"""
    lags = {}
    
    for i, source_service in enumerate(service_names):
        for j, target_service in enumerate(service_names):
            if i != j:
                # ç›¸äº’ç›¸é–¢ã«ã‚ˆã‚‹é…å»¶æ¤œå‡º
                correlation = cross_correlation(
                    temporal_features[:, i], 
                    temporal_features[:, j],
                    max_lag=window_size
                )
                lags[f"{source_service}->{target_service}"] = {
                    'optimal_lag': np.argmax(correlation),
                    'correlation_strength': np.max(correlation)
                }
    
    return lags
```

### 2. ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹å› æœæ¨å®š

```python
def graph_based_causality(service_graph, causal_scores):
    """ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’è€ƒæ…®ã—ãŸå› æœé–¢ä¿‚æ¨å®š"""
    
    # PageRankã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹å½±éŸ¿åº¦è¨ˆç®—
    adjacency = service_graph.adjacency_matrix
    influence_scores = pagerank(adjacency, causal_scores)
    
    # æœ€çŸ­ãƒ‘ã‚¹ã«ã‚ˆã‚‹å› æœãƒã‚§ãƒ¼ãƒ³æ¤œå‡º
    causal_chains = []
    for root_cause in high_probability_causes:
        paths = shortest_paths(adjacency, root_cause)
        causal_chains.extend(paths)
    
    return influence_scores, causal_chains
```

### 3. ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯

```python
def multimodal_consistency_check(metrics_causality, log_causality, graph_causality):
    """è¤‡æ•°ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã§ã®å› æœé–¢ä¿‚ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
    
    consistency_scores = {}
    
    for service in service_names:
        metric_score = metrics_causality.get(service, 0)
        log_score = log_causality.get(service, 0)
        graph_score = graph_causality.get(service, 0)
        
        # ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ = ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®åˆæ„åº¦
        consistency = 1.0 - np.std([metric_score, log_score, graph_score])
        consistency_scores[service] = consistency
    
    return consistency_scores
```

## å®Ÿè¡Œä¾‹

### ã‚µãƒ³ãƒ—ãƒ«ã®å®Ÿè¡Œ

```bash
# å› æœé–¢ä¿‚æŠ½å‡ºãƒ‡ãƒ¢ã®å®Ÿè¡Œ
python causal_extraction_example.py
```

æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ï¼š
```
ğŸ” OCEANå› æœé–¢ä¿‚æŠ½å‡ºã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
==================================================
ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ã‚·ãƒŠãƒªã‚ªã‚’ä½œæˆä¸­...
ğŸ¤– OCEANãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...
ğŸ”¬ å› æœé–¢ä¿‚æŠ½å‡ºå™¨ã‚’åˆæœŸåŒ–ä¸­...
ğŸ¯ å› æœé–¢ä¿‚ã‚’æŠ½å‡ºä¸­...

ğŸ“‹ åˆ†æçµæœ:
------------------------------
æœ€æœ‰åŠ›æ ¹æœ¬åŸå› : database
ç¢ºä¿¡åº¦: 0.847

æ ¹æœ¬åŸå› å€™è£œæ•°: 3

ä¸Šä½æ ¹æœ¬åŸå› å€™è£œ:
  1. database: 0.847 (high)
  2. user-service: 0.623 (medium)
  3. api-gateway: 0.456 (medium)

ğŸŒ ã‚µãƒ¼ãƒ“ã‚¹å½±éŸ¿åº¦åˆ†æ:
  database:
    å¤–å‘ãå½±éŸ¿: 2.341
    å†…å‘ãå½±éŸ¿: 0.123
    å½±éŸ¿æ¯”ç‡: 19.024
  user-service:
    å¤–å‘ãå½±éŸ¿: 1.245
    å†…å‘ãå½±éŸ¿: 1.876
    å½±éŸ¿æ¯”ç‡: 0.664

â° æ™‚ç³»åˆ—å› æœé–¢ä¿‚åˆ†æ:
  å¤‰åŒ–ç‚¹:
    database (æ™‚åˆ»10): 2.156
    user-service (æ™‚åˆ»12): 1.534
    api-gateway (æ™‚åˆ»14): 0.923

ğŸ‰ å› æœé–¢ä¿‚æŠ½å‡ºãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†!
```

## çµæœã®æ´»ç”¨æ–¹æ³•

### 1. ã‚¢ãƒ©ãƒ¼ãƒˆå„ªå…ˆåº¦ä»˜ã‘

```python
def prioritize_alerts(causal_results, current_alerts):
    """å› æœé–¢ä¿‚ã«åŸºã¥ãã‚¢ãƒ©ãƒ¼ãƒˆå„ªå…ˆåº¦ä»˜ã‘"""
    
    prioritized_alerts = []
    root_causes = causal_results['summary']['likely_root_causes']
    
    for alert in current_alerts:
        service = alert['service']
        priority_boost = 0
        
        # æ ¹æœ¬åŸå› å€™è£œã®å ´åˆã¯å„ªå…ˆåº¦ã‚’ä¸Šã’ã‚‹
        for cause in root_causes:
            if cause['service'] == service:
                priority_boost = cause['probability'] * 10
                break
        
        alert['priority'] += priority_boost
        prioritized_alerts.append(alert)
    
    return sorted(prioritized_alerts, key=lambda x: x['priority'], reverse=True)
```

### 2. è‡ªå‹•ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

```python
def suggest_remediation_actions(causal_results):
    """å› æœé–¢ä¿‚ã«åŸºã¥ãä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ"""
    
    actions = []
    top_cause = causal_results['summary']['top_root_cause']
    
    if top_cause:
        service = top_cause['service']
        confidence = top_cause['probability']
        
        if service == 'database' and confidence > 0.8:
            actions.append({
                'action': 'scale_database_replicas',
                'priority': 'high',
                'description': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¬ãƒ—ãƒªã‚«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°'
            })
            actions.append({
                'action': 'enable_query_caching',
                'priority': 'medium',
                'description': 'ã‚¯ã‚¨ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹åŒ–'
            })
        
        elif service == 'api-gateway' and confidence > 0.7:
            actions.append({
                'action': 'increase_rate_limits',
                'priority': 'high',
                'description': 'ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®èª¿æ•´'
            })
    
    return actions
```

### 3. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆ

```python
def create_causality_dashboard(causal_results):
    """å› æœé–¢ä¿‚ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ä½œæˆ"""
    
    dashboard_data = {
        'timestamp': datetime.now().isoformat(),
        'root_cause_summary': causal_results['summary'],
        'service_health_scores': {},
        'causal_graph': {},
        'recommendations': suggest_remediation_actions(causal_results)
    }
    
    # ã‚µãƒ¼ãƒ“ã‚¹å¥å…¨æ€§ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
    influences = causal_results['service_influences']
    for service, influence in influences.items():
        health_score = 1.0 - (influence['incoming_influence'] / 10.0)
        dashboard_data['service_health_scores'][service] = max(0, min(1, health_score))
    
    return dashboard_data
```

## ã¾ã¨ã‚

OCEANã«ã‚ˆã‚‹å› æœé–¢ä¿‚æŠ½å‡ºã¯ä»¥ä¸‹ã®æ‰‹é †ã§å®Ÿè¡Œã•ã‚Œã¾ã™ï¼š

1. **ãƒ‡ãƒ¼ã‚¿æº–å‚™**: æ™‚ç³»åˆ—ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ãƒ­ã‚°ã€ã‚µãƒ¼ãƒ“ã‚¹ã‚°ãƒ©ãƒ•ã®ç”¨æ„
2. **ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œ**: OCEANãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¨è«–
3. **å› æœé–¢ä¿‚æŠ½å‡º**: æ³¨æ„é‡ã¿ã€ã‚°ãƒ©ãƒ•æ§‹é€ ã€æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ
4. **çµæœè§£é‡ˆ**: æ ¹æœ¬åŸå› ã®ç‰¹å®šã¨å½±éŸ¿åº¦ã®è©•ä¾¡
5. **ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ**: ä¿®å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å„ªå…ˆåº¦ä»˜ã‘

ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ç’°å¢ƒã«ãŠã‘ã‚‹ç•°å¸¸ã®æ ¹æœ¬åŸå› ã‚’åŠ¹æœçš„ã«ç‰¹å®šã—ã€è¿…é€Ÿãªå•é¡Œè§£æ±ºã‚’æ”¯æ´ã§ãã¾ã™ã€‚